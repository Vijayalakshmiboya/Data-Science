# Data-Science
Linear Regression in Google Colab
ğŸ“Œ Overview

This project demonstrates Linear Regression using Python in Google Colab. It includes data preprocessing, model training, visualization, and evaluation with metrics like MSE, RMSE, and RÂ² score.

ğŸ§® What is Linear Regression?

Linear Regression models the relationship between dependent and independent variables by fitting a straight line:
y=Î²0â€‹+Î²1â€‹x+Ïµ

Where:

y â†’ Dependent variable (target)

x â†’ Independent variable (feature)

Î²0 â†’ Intercept

Î²1 â†’ Coefficient

Îµ â†’ Error term

ğŸš€ Features

Simple Linear Regression (1 variable)

Multiple Linear Regression (multi-features)

Data preprocessing (handling missing values, normalization)

Visualization with Matplotlib/Seaborn

Model evaluation metrics (MSE, RMSE, RÂ²)

ğŸ“‚ Project Structure

Since Colab is notebook-based, files are minimal:

â”œâ”€â”€ Linear_Regression.ipynb   # Main Google Colab notebook
â”œâ”€â”€ data/                     # (Optional) dataset uploaded to Colab
â””â”€â”€ README.md                 # Documentation

âš™ï¸ Setup in Google Colab

Open Google Colab
.

Upload the Linear_Regression.ipynb notebook.

(Optional) Upload dataset (CSV) to the Colab environment:

from google.colab import files
uploaded = files.upload()  # Choose your dataset.csv


Install dependencies (usually pre-installed in Colab):

!pip install numpy pandas matplotlib seaborn scikit-learn

ğŸ–¥ï¸ Usage

Open and run each cell in Linear_Regression.ipynb.

Load dataset:

import pandas as pd
df = pd.read_csv("your_dataset.csv")


Train the model using scikit-learn:

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

X = df[['feature_column']]
y = df['target_column']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)


Evaluate performance:

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("MSE:", mse)
print("RMSE:", rmse)
print("RÂ² Score:", r2)


Visualize regression line:

import matplotlib.pyplot as plt

plt.scatter(X_test, y_test, color="blue")
plt.plot(X_test, y_pred, color="red", linewidth=2)
plt.xlabel("Feature")
plt.ylabel("Target")
plt.title("Linear Regression Fit")
plt.show()

ğŸ“Š Example Output

Regression line plotted over data points

Evaluation metrics like:

MSE: 12.45
RMSE: 3.53
RÂ² Score: 0.87

ğŸ”® Future Improvements

Add Polynomial Regression

Implement Regularization (Ridge, Lasso)

Use cross-validation

ğŸ‘‰ Do you want me to also give you a ready-made Colab noteboo
